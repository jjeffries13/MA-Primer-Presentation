---
title: " "

output:
  xaringan::moon_reader:
    css: ["xaringan-themer.css"]
    nature:
      highlightStyle: solarized-dark
      highlightLines: true
      countIncrementalSlides: false
---
```{r xaringan-themer, include=FALSE, warning=FALSE}
library(xaringanthemer)
library(knitr)
library("metafor")
library("robumeta")
library("puniform")
library("metaviz")
library("ggplot2")
library("ggforce")
library("dplyr")
library(ggthemes)
library(ggridges)
library(tidyverse)
library(ggpubr)
library(rstatix)
library(broom)
library(Matrix)
library(corrplot)
library(gtsummary)
library(pwr)
library(forester)

style_solarized_dark()
```
class: inverse, center, middle
background-image: url(https://img.rawpixel.com/s3fs-private/rawpixel_images/website_content/rm283-nunny-055_1.jpg?w=1000&dpr=1&fit=default&crop=default&q=65&vib=3&con=3&usm=15&bg=F4F4F3&ixlib=js-2.2.1&s=0503dd0e4320aa87005543d9bc7ebfe4)
background-size: cover

<h1 style="color:white;font-size:40px;"> A Primer for Conducting a Meta-Analysis </h1>

<img src="https://d33wubrfki0l68.cloudfront.net/7e89f71ee68cff45427e783fdc58510a9e32dfc9/0da76/wp-content/uploads/2018/10/rstudio-logo-white.png" width="200px"/>
<p1 style="color:white;font-size:25px;"> USING ROBUMETA, META-VIZ, and FORESTER </p1>

<p2 style="color:white;font-size:16px;">
.large[Jay Jeffries & Jonah Garbin | Seminar | 22 Oct 2021]</p1>

---
class: inverse
## Agenda

- <font size="9"> Introduction </font>

- <font size="9"> General Steps in Conducting </font>

- <font size="9"> Jonah's Meta-Analysis </font>

- <font size="9"> Jay's Meta-Analysis </font>

- <font size="9"> Thoughts and Questions </font>

---
class: middle
## Differentiating Methodology

- Literature Review: Qualitatively summarizes a collection of literature within a field of study through use of subjective, interpretive, less formal techniques.
  - Provides context and background information for a line of research.

- Systematic Review: Synthesizes screened works from pre-specified eligibility criteria to appraise quality and validity of studies to answer a research question.
  - “Systematic” defines the method of transparency and reproducibility to minimize bias (i.e. cherry-picking) when selecting studies.

- **Meta-Analysis: Statistically describes study outcomes derived from a screened sample of articles or unpublished works via a common metric (e.g. d, g, r, OR, Cramer’s V).**
  - **Results in the _robust_ calculation and interpretation of an overall estimated effect size for a relationship or intervention of interest.**
---
class: inverse, middle

# Rationale: *Why Meta-Analysis*?

You want to estimate the average effect (or variance) from a set of studies

<p2 style="font-size:12px;"> Example: When all scores are included in the analysis, children classified with speech language impairement scored lower on writing measures than their typically developing peers (*g* = −0.97). </p2>

```{r, echo = FALSE, fig.align = "center"}
knitr::include_graphics("https://github.com/jjeffries13/MA-Primer-Presentation/blob/main/Images/Graham.png?raw=true")
```

---
class: inverse, middle

# Rationale: *Why Meta-Analysis*?

You want to explore variations or probe moderators across study results

<p2 style="font-size:12px;"> Example: The studies indicated that visual art therapy significantly reduced depressive symptoms (<i>g</i> = −0.380 [−0.693, −0.067], <i>p</i> = .017) anxiety symptoms (<i>g</i> = −0.263, [−0.482, −0.044], <i>p</i> = .019). </p2>

```{r, echo = FALSE, fig.align = "center"}
knitr::include_graphics("https://github.com/jjeffries13/MA-Primer-Presentation/blob/main/Images/Masika.png?raw=true")
```

---
class: inverse, middle

# Rationale: *Why Meta-Analysis*?

You want to identify bias in the existing reported literature

<p2 style="font-size:12px;"> Example: Egger’s regression test produced nonsignificant results ( &beta; = .57, <i>p</i> = .26). The trim and fill procedure to address publication
bias revealed that 1 negative result was missing from the bystander intervention outcomes, but the imputed missing value did not change the overall statistical significance. These results show publication bias did not significantly impact outcomes. </p2>

```{r, echo = FALSE, out.height = "300px", fig.align = "center"}
knitr::include_graphics("https://github.com/jjeffries13/MA-Primer-Presentation/blob/main/Images/Polanin.png?raw=true")
```
---
class: 
## Steps To Conducting a Meta-Analysis

1. <font size="5"> Formulate Research Questions </font>

2. <font size="5"> Literature Search </font>

3. <font size="5"> Screen the Literature </font>

4. <font size="5"> Code the Studies </font>

5. <font size="5"> Visualize Data </font>

6. <font size="5"> Statistically Describe Effect Sizes </font>

7. <font size="5"> Data and Bias Diagnostics </font>

8. <font size="5"> Interpreting Outcomes </font>

9. <font size="5"> Presenting Results </font>

10. <font size="5"> I like even numbers so CELEBRATE at step 10 </font>

.footnote[
<small>Cooper, Hedges, & Valentine (2019) <i>The Handbook Of Research
Synthesis and Meta-Analysis</i></small>

<small>Pigott, Polanin, Williams (2021) <i>AERA-ICPSR Workshop</i> </small>
]
---
class: inverse

## 1. Formulate Research Question

### Routes to consider...

- *Intervention Effectiveness*: how effective is an intervention or group of interventions?
  - E.g. What is the impact of a specific simulation-based learning intervention on new graduate nurse self-efficacy?
  
- *Relationships*: how are these constructs related to one another?
  - E.g. How is student civic engagement associated with school pride?
  
- *Prevalence*: how likely is the occurrence of a condition?
  - E.g. What is the difference in likelihood of ACL tear across sex for basketball athletes?
  
---
class: inverse

## 1. Formulate Research Question

### Routes to consider...
  
- *Instrument Diagnostics*: how well does an instrument or test predict a condition across conditions or groups?
  - How well does the WISC-V intelligence scale evaluate students of ELL status?
  - May be worthwhile before conducting a replication study
  
- *Comparative Effectiveness*: how do interventions or instruments compare or relate to one another?
  - How does the Marlowe-Crowne Social Desirability Scale compare to the Brief Social Desirability Scale when assessing those applying for management positions?
  - Great for evaluating feasibility of a cheaper program when compared to a more expensive program
---
class: middle

## 1. Formulate Research Questions
### Defining Research Criteria 
#### Helpful for Literature Searching!

**P** - Population, Participants

**I** - Independent Variables (or predictors)

**C** - Conditions (settings, contexts, time frame)

**O** - Outcomes (measures, dependent variables, criterion)

**S** - Study design 

.footnote[
<small>An adaptation of Cronbach's <i>UTOS</i> framework</small>
]
---
class: inverse
## 2. Literature Search
### Database Searching

Use your **PICOS** information to create Boolean operators to commune with the literature, improve the yield, and make this process as easy as possible. 
- Update search term list as you become more familiar with the literature

```{r, out.height= "50%", out.width= "70%", echo = FALSE, fig.align='center'}
knitr::include_graphics("https://github.com/jjeffries13/MA-Primer-Presentation/blob/main/Images/BOO-leanOperator.jpeg?raw=true")
```

Your aim is to capture all plausible content relevant to your research question!

---
class: inverse, middle
## 2. Literature Search
### Database Searching

Select databases, journals that are prevalent to your field of research. 
- Unsure about this? Contact our library liason, [Erica DeFrain](https://directory.unl.edu/people/edefrain2). 

Ensure that you are including a search for *unpublished* research
- ProQuest Dissertation & Theses, EBSCO Open Dissertations, Open Access Dissertation and Theses (OATD)
- Document delivery systems -- Interlibrary Loan/ILLiad
- Contact author(s)

Locating unpublished research is, inevitably, be difficult
- Feeds the phenomenon of Publication Bias

---
class: inverse
## 2. Literature Search
#### [Citation Searching and Footnote Chasing](https://libguides.williams.edu/citationsearching/introduction)
.pull-left[
1. Backward citation search: looking at the works cited by an author
]
.pull-right[
2. Forward citation search: following where a work has been cited after its publication
]

Create boundaries. Know when to stop searching. This *could* go on forever. 

```{r, out.height= "70%", out.width= "80%", echo = FALSE, fig.align='center'}
knitr::include_graphics("https://github.com/jjeffries13/MA-Primer-Presentation/blob/main/Images/Screen%20Shot%202021-10-18%20at%2011.21.41%20AM.png?raw=true")
```

<small>Sherman et al. (2009)</small>

---
class: middle
### Database Search Example
```{r, out.height= "60%", out.width= "80%", echo = FALSE, fig.align='center'}
knitr::include_graphics("https://github.com/jjeffries13/MA-Primer-Presentation/blob/main/Images/Screen%20Shot%202021-10-18%20at%2011.04.38%20AM.png?raw=true")
```

---
class: inverse
## 2. Literature Search
### Managing Search Results
.pull-left[
To record your selection process pull all journal, database, and citation search results into an reference manager.
- Zotero
- Mendelay
- EndNotes
- RefWorks

Export content into Excel (or some equivalent) to assess criteria in the screening step
]
.pull-left[
```{r, out.height= "70%", out.width= "90%", echo = FALSE, fig.align='right'}
knitr::include_graphics("https://github.com/jjeffries13/MA-Primer-Presentation/blob/main/Images/Screen%20Shot%202021-10-18%20at%201.29.34%20PM.png?raw=true")
```
]
---
class: middle, inverse
## 3. Screen the Literature

To identify articles eligible for review, you will go through a process of screening
1. Your first phase of screening: filter though abstract or titles
2. Your second phase of screening: filter whole-document 

Things you are looking for:
- Evidence of your **PICOS** list; i.e. inclusion and exclusion criteria
- The I.V.(s) and D.V.(s) that you are interested in
- Areas to update your search term list
- Potential moderators of interest 
  - What other common factors impact your RQ's? Write these down!
- An *effect size*

---
class: middle
### Defining Form of Effect Size

This decision should be informed by:
- your research question 
- your field of research and audience (education, psychology, medicine?)
- how you wish to interpret your findings

You typically select from one of three families: 
1. Mean difference
2. Proportion
3. Association

```{r, out.height= "50%", out.width= "80%", echo = FALSE, fig.align='center'}
knitr::include_graphics("https://github.com/jjeffries13/MA-Primer-Presentation/blob/main/Images/effect_sizes.jpeg?raw=true")
```
---
class: middle
### Types of Effect Sizes (ES)

<u>Effects Based on Means (Standardized)</u>
- Cohen's *d*: difference between groups in terms of standard deviations
- Hedge's *g*: small sample correction (when *n* &#8804; 20) version of *d*
- Glass's &Delta;: uses untainted SD of control group (use when SDs are sig. different)

---
class: middle
### Types of Effect Sizes (ES)

<u>Effects Based on Binary Proportion Data</u>
- Odds Ratio *OR*: ratio of events (e.g. lung cancer in smoker) to non-events (e.g. lung cancer in non-smokers)
- Risk Ratio *RR*: ratio of two proportions to show relative risk 
- Risk Differences *RD*: attributable risk difference between two groups

---
class: middle
### Types of Effect Sizes (ES)

<u>Effects Based on Association</u>
- Pearson product-moment correlation coefficient *r*: measure of association between two continuous variables
- Point-biserial correlation <i>r<sub>pb</sub></i>: measure of association when one variable is dichotomous
- Phi coefficient &Phi; : measure of association when both variables are dichotomous
---
class: inverse

## 3. Screen the Literature
### Effect Size Calculators and Converters

When you run into: 
- an F-statistic that you need translated into a Cohen's *d*
- a &beta; that you must identify as an *r*
- a Risk Ratio that you wish were a Hedge's *g*
- a &#120536;<sup>2</sup> value that needs to be an *OR*

Use these resources or create your own Excel/R calculators

[Campbell's Collaboration](https://www.campbellcollaboration.org/research-resources/effect-size-calculator.html)

[Psychometrica](https://www.psychometrica.de/effect_size.html)

[escal](https://www.escal.site/#)
---
class: 
## Standard Reporting
Transparent reporting is inherent in meta-analyses, and requires you to track your literature search.
- Allows others to audit your search, replicate, and confirm your findings
  - Validity and honesty of your research practice (you have "*the receipts*"!)
- Concurrent with your search, screening, and quality appraisal process

<small> Recommended [PRISMA Guidelines](http://www.prisma-statement.org/PRISMAStatement/PRISMAEandE)</small>
```{r, out.height= "50%", out.width= "70%", fig.align ='center', echo = FALSE}
knitr::include_graphics("https://github.com/jjeffries13/MA-Primer-Presentation/blob/main/Images/PRISMA(2020).png?raw=true")
```
<small>[Shiny app](https://estech.shinyapps.io/prisma_flowdiagram/) to automate the creation of your flow diagram.</small>

---
class: middle
## 4. Code the Studies
#### Codebook and Moderators

.pull-left[General information
- article title, author, study number, effect size ID, publication type

Participant information
- sample size, % female, race/ethnicity indicators, average age, % diagnosed, etc.

Measure information
- name of instrument, scale, metric
]
.pull-left[
```{r, echo = FALSE, fig.align='center'}
knitr::include_graphics("https://github.com/jjeffries13/MA-Primer-Presentation/blob/main/Images/MagnifyingGlass.gif?raw=true")
```
]
---
class: middle
## 4. Code the Studies
#### Codebook and Moderators
.pull-left[
Effect size information
- effect size statistic, variance, upper/lower CI, Fisher's z score
]
.pull-right[
```{r, out.height= "50%", out.width= "70%", fig.align ='center', echo = FALSE}
knitr::include_graphics("https://github.com/jjeffries13/MA-Primer-Presentation/blob/main/Images/garbageingarbageout11.png?raw=true")
```
]
Study Quality information
- measurement reliability (sample/manual), article quality tool, study power
---
class: middle
## 5. Visualize the Data

```{r Reading in Technostress Data, echo = FALSE}
TechnostressData <- read.csv("/Users/jayjeffries/Desktop/Meta-Analysis/Technostress_Codebook.csv", header = TRUE, sep = ",")
TechnostressData <- TechnostressData[1:139,]
TechnostressData[TechnostressData == -999] <- NA

TechnostressData$K12 <- ifelse(TechnostressData$school_type == "0", 1, 0)
TechnostressData$higher <- ifelse(TechnostressData$school_type == "1", 1, 0)
TechnostressData$school_type <- factor(TechnostressData$school_type)
TechnostressData$latent_var <- factor(TechnostressData$latent_var)
TechnostressData$anx <- ifelse(TechnostressData$latent_var == "0", 1, 0)
TechnostressData$dep <- ifelse(TechnostressData$latent_var == "1", 1, 0)
TechnostressData$fatigue <- ifelse(TechnostressData$latent_var == "2", 1, 0)

TechnostressData$latent_var[TechnostressData$latent_var == 2] <- NA
```



---
class: inverse
## 6. Statistically Describe Effect Sizes

Effect sizes have the advantage of being comparable across all screened studies 
  - To do so, each ES needs a standard error, which are vital to the 

Effect size dependencies create an implied multilevel structure

```{r, out.height= "60%", out.width= "80%", fig.align ='center', echo = FALSE}
knitr::include_graphics("https://github.com/jjeffries13/MA-Primer-Presentation/blob/main/Images/MultilevelES.png?raw=true")
```
<small> Effect size nested within a sample, nested within an study, within an article, within a population </small>
---
class: 
### Type of Model

| Fixed Effect                                                    | Random Effect                                                            |
|-----------------------------------------------------------------|--------------------------------------------------------------------------|
| One true effect                                                 | True effect varies                                                       |
| Effects from a single, homogeneous population                   | Effects from a distribution of effect sizes                              |
| Differences between studies are due only to sampling error      | Differences between studies are due many factors                         |
| Larger studies are more influential                             | Studies weighted in a balanced way                                       |
| Only account for within-study heterogeneity & error             | Accounts for within-study and between-study heterogeneity & error        |
| Goal is to find the one true effect size that all studies share | Goal is to find the average effect from the distribution of effect sizes |
| Often used for smaller sample of articles                       | Difficult to understand heterogeneity in small sample of articles        |

<small>Borenstein et al. (2010)</small>
---
### Type of Model

```{r, out.height= "60%", out.width= "80%", fig.align ='center', echo = FALSE}
knitr::include_graphics("https://github.com/jjeffries13/MA-Primer-Presentation/blob/main/Images/Screen%20Shot%202021-10-18%20at%203.21.05%20PM.png?raw=true")
```
---
### Type of Model

```{r, out.height= "60%", out.width= "80%", fig.align ='center', echo = FALSE}
knitr::include_graphics("https://github.com/jjeffries13/MA-Primer-Presentation/blob/main/Images/FEvsRE.jpg?raw=true")
```
---
class: inverse
### Fixed Effects Model

.pull-left[
```{r, out.height= "60%", out.width= "80%", fig.align ='center', echo = FALSE}
knitr::include_graphics("https://github.com/jjeffries13/MA-Primer-Presentation/blob/main/Images/FEModel.png?raw=true")
```
]
.pull-right[
Strong assumption: effect sizes are homogeneous
- Reserve for instances where studies are *close* replications of one another

One source of variability: 
- sampling error (*SE*<sub>i</sub>)
- while *w*<sub>i</sub> indicates ES weight
]
.pull-left[
```{r, out.height= "40%", out.width= "50%", fig.align ='center', echo = FALSE, fig.show='hold'}
knitr::include_graphics("https://github.com/jjeffries13/MA-Primer-Presentation/blob/main/Images/FE_ES.png?raw=true")
```
]
.pull-right[
```{r, out.height= "30%", out.width= "50%", fig.align ='center', echo = FALSE, fig.show='hold'}
knitr::include_graphics("https://github.com/jjeffries13/MA-Primer-Presentation/blob/main/Images/Fix_SE.png?raw=true")
```
]

<small>Pigott, Polanin, Williams (2021) <i>AERA-ICPSR Workshop</i> </small>
---
class: inverse
### Random Effects Model

.pull-left[
```{r, out.height= "60%", out.width= "80%", fig.align ='center', echo = FALSE}
knitr::include_graphics("https://github.com/jjeffries13/MA-Primer-Presentation/blob/main/Images/REModel.png?raw=true")
```
]
.pull-right[
Harder to rule out a random effects model unless sterile conditions, carefully scripted, and precise replications

Two sources of variability: 
- sampling error (*SE*<sub>i</sub>) 
-  between-study variance (&tau;<sup>2</sup>)
- *w*<sub>i</sub> still indicates ES weight
]
.pull-left[
```{r, out.height= "40%", out.width= "50%", fig.align ='center', echo = FALSE, fig.show='hold'}
knitr::include_graphics("https://github.com/jjeffries13/MA-Primer-Presentation/blob/main/Images/FE_ES.png?raw=true")
```
]
.pull-right[
```{r, out.height= "40%", out.width= "50%", fig.align ='center', echo = FALSE, fig.show='hold'}
knitr::include_graphics("https://github.com/jjeffries13/MA-Primer-Presentation/blob/main/Images/Rand_SE.png?raw=true")
```
]

<small>Pigott, Polanin, Williams (2021) <i>AERA-ICPSR Workshop</i> </small>
---
## Resources
[Doing Meta-Analysis in R](https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/)
- <small>Online Text
- Advanced sections: MLM M-A, SEM M-A, Network M-A, Bayesian M-A</small>

[{robumute} Vignette](https://cran.r-project.org/web/packages/robumeta/vignettes/robumetaVignette.pdf)
- <small>RVE Meta-Regression, Publication Bias Assessments</small>

[{metaviz} Vignette](https://cran.r-project.org/web/packages/metaviz/vignettes/metaviz.html)
- <small>Power Sunset Plots</small>

[{forester} GitHub Page (WIP!)](https://github.com/rdboyes/forester/)
- <small>Publication-Ready Forest Plots</small>

---
## References

---
# Thoughts and Questions